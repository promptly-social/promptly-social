import os
import random
from typing import Any, Dict, List, Optional

from pydantic import BaseModel, Field
from pydantic_ai.models.openai import OpenAIModel, OpenAIModelSettings
from pydantic_ai.providers.openrouter import OpenRouterProvider
from pydantic_ai import Agent


class FilteredArticlesResult(BaseModel):
    """Schema for the filtered articles result."""

    ids: List[str] = Field(description="A list of article ids.")


class GeneratedPost(BaseModel):
    """Schema for the post generated by the AI agent."""

    linkedin_post: str = Field(description="The generated LinkedIn post content.")
    topics: List[str] = Field(
        description="A list of relevant topics for the post: Education, Story-telling, Analysis, Validation, and/or Promotion."
    )


class PostsGenerator:
    def __init__(self):
        self.openrouter_api_key = os.getenv("OPENROUTER_API_KEY")

        # Get large model configuration from environment variables for posts generation
        self.large_model_primary = os.getenv(
            "OPENROUTER_LARGE_MODEL_PRIMARY", "google/gemini-2.5-pro"
        )
        large_models_fallback_str = os.getenv(
            "OPENROUTER_LARGE_MODELS_FALLBACK", "deepseek/deepseek-r1-0528"
        )
        self.large_models_fallback = [
            model.strip() for model in large_models_fallback_str.split(",")
        ]
        self.large_model_temperature = float(
            os.getenv("OPENROUTER_LARGE_MODEL_TEMPERATURE", "0.0")
        )

        self.model_primary = os.getenv(
            "OPENROUTER_MODEL_PRIMARY", "google/gemini-2.5-flash"
        )
        models_fallback_str = os.getenv(
            "OPENROUTER_MODELS_FALLBACK", "deepseek/deepseek-r1-0528"
        )
        self.models_fallback = [
            model.strip() for model in models_fallback_str.split(",")
        ]
        self.model_temperature = float(os.getenv("OPENROUTER_MODEL_TEMPERATURE", "0.0"))

    def _prepare_articles_for_filtering(self, candidate_posts: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        Prepare articles for filtering by converting IDs to strings.
        """
        prepared_posts = []
        for post in candidate_posts:
            post_copy = post.copy()

            # Convert UUID to string
            if "id" in post_copy and hasattr(post_copy["id"], "__str__"):
                post_copy["id"] = str(post_copy["id"])

            prepared_posts.append(post_copy)

        return prepared_posts



    async def filter_articles(
        self,
        candidate_posts: List[Dict[str, Any]],
        bio: str,
        topics_of_interest: List[str],
        number_of_posts_to_generate: int,
    ) -> List[Dict[str, Any]]:
        """
        Filter the articles based on the user's bio and topics of interest.
        Uses individual article evaluation with shuffling for randomness.
        """

        print(f"{len(candidate_posts)} candidate posts are being filtered.")

        if not candidate_posts:
            return []

        # Prepare articles for filtering (convert IDs to strings)
        prepared_posts = self._prepare_articles_for_filtering(candidate_posts)

        # Shuffle the posts for randomness before processing
        random.shuffle(prepared_posts)
        print("Shuffled articles for random selection order")

        # Use individual processing for all articles
        selected_ids = await self._filter_articles_individually(
            prepared_posts, bio, topics_of_interest, number_of_posts_to_generate
        )
        print(f"{len(selected_ids)} articles were selected: {selected_ids}")

        if len(selected_ids) == 0:
            print(
                "No articles were found that match the user's bio and topics of interest."
            )
            return []

        # Map selected IDs back to original posts (with full content)
        filtered_articles = []
        for selected_id in selected_ids:
            for original_post in candidate_posts:
                post_id = str(original_post.get("id")) if hasattr(original_post.get("id"), "__str__") else original_post.get("id")
                if post_id == selected_id:
                    # Create a copy with string ID for consistency
                    post_copy = original_post.copy()
                    post_copy["id"] = post_id
                    filtered_articles.append(post_copy)
                    break

        if len(filtered_articles) < number_of_posts_to_generate:
            print(
                f"{len(filtered_articles)} articles were found that match the user's bio and topics of interest."
            )

        return filtered_articles

    async def _filter_articles_individually(
        self,
        prepared_posts: List[Dict[str, Any]],
        bio: str,
        topics_of_interest: List[str],
        number_of_posts_to_generate: int,
    ) -> List[str]:
        """
        Filter articles one by one for maximum reliability.
        Processes articles in shuffled order until we have enough selections.
        """
        selected_articles = []

        for post in prepared_posts:
            if len(selected_articles) >= number_of_posts_to_generate:
                break

            try:
                # Process each article individually
                is_suitable = await self._evaluate_single_article(
                    post, bio, topics_of_interest
                )

                if is_suitable:
                    selected_articles.append(post["id"])
                    print(f"Selected article: {post.get('title', 'No title')} (ID: {post['id']})")

            except Exception as e:
                print(f"Error evaluating article {post.get('id')}: {e}")
                continue

        return selected_articles

    async def _evaluate_single_article(
        self,
        article: Dict[str, Any],
        bio: str,
        topics_of_interest: List[str],
    ) -> bool:
        """
        Evaluate a single article for suitability.
        Returns True if the article should be selected.
        """
        # Trim content if it's very long to avoid token limits
        content = article.get('content', 'No content')
        if len(content.split()) > 500:  # If more than 500 words, take first 500
            content_words = content.split()[:500]
            content = " ".join(content_words) + "..."

        prompt = f"""Evaluate this single article to determine if it would make a compelling LinkedIn post.

**User Profile:**
- **Bio:** {bio}
- **Topics of Interest:** {topics_of_interest}

**Article to Evaluate:**
- **Title:** {article.get('title', 'No title')}
- **Subtitle:** {article.get('subtitle', 'No subtitle')}
- **Content:** {content}

**Evaluation Criteria:**
- Does it present thought-provoking content with strong opinions or unique perspectives?
- Would it encourage discussion and comments on LinkedIn?
- Is it relevant to the user's expertise and topics of interest?
- Does it have broader appeal beyond niche product updates?

**Avoid:**
- Software updates, product announcements, simple news reports
- Company-specific hiring or internal news

**Instructions:**
Respond with ONLY "YES" if this article would make a compelling LinkedIn post, or "NO" if it would not.
"""

        model = OpenAIModel(
            self.model_primary,
            provider=OpenRouterProvider(
                api_key=self.openrouter_api_key,
            ),
        )

        agent = Agent(
            model,
            output_type=str,
            model_settings=OpenAIModelSettings(
                temperature=self.model_temperature,
                extra_body={"models": self.models_fallback},
            ),
            system_prompt="You are an expert Content Strategist who evaluates articles for LinkedIn post potential.",
        )

        try:
            result = await agent.run(prompt)
            response_text = result.output.strip().upper()
            return response_text == "YES"
        except Exception as e:
            print(f"Error evaluating single article: {e}")
            return False

    async def generate_post(
        self,
        idea_content: str,
        bio: Optional[str],
        writing_style: Optional[str],
        linkedin_post_strategy: Optional[str],
    ) -> GeneratedPost:
        """
        Generates a LinkedIn post using the AI agent.
        """

        prompt = f"""You are a world-class LinkedIn Ghostwriter and Content Strategist. Your expertise is in taking a piece of source material (like an article) and transforming it into a compelling, authentic-sounding LinkedIn post that drives engagement and positions the user as a thought leader.

**Context for this Task:**

1. **Author's Profile:**
    -   **Bio:** {bio}
    -   **Writing Style:** {writing_style}

2. **Specific Post Instructions:**
    -   **LinkedIn Post Style:** {linkedin_post_strategy}
    This is a specific directive on the format and style of the post. You must follow it closely.

**Your Task & Thought Process:**

1.  **Deconstruct the Source:** Read the `Source Material` and identify its single most important takeaway or a surprising insight. Don't just summarize.
2.  **Connect to the Author:** How can this key takeaway be framed from the author's perspective, using their `Bio` and expertise? How can they add a personal story or a strong opinion to it?
3.  **Draft the Post:** Write the post following the `LinkedIn Post Style` and mimicking the author's `Writing Style`.

**LinkedIn Post Best Practices to Apply:**

-   **Use conversation insights**: If the user shared personal experiences, anecdotes, or specific perspectives in the conversation, incorporate them into the post
-   **Provide their unique take**: Use the conversation context to understand their specific angle or opinion
-   **Be human and authentic**: Write in a conversational tone. Use "I" statements. Use the user's writing style and any personal details they've shared
-   **Structure for readability**: Use short paragraphs and white space

**VERY IMPORTANT - Formatting and Content Rules:**

-   **Plain Text Only:** The entire post must be plain text. Do NOT use any Markdown formatting (like `*bold*`, `_italics_`, or `- lists`).
-   **No AI- giveaways:** Avoid generic phrases, emojis, or special characters (like em-dashes or arrows) that scream "AI-generated".
-   **Do Not make up personal anecdotes:** The post must be based on the source material. Do not fabricate personal anecdotes or experiences if not provided in the user's bio.
-   **No Source Link:** Do NOT include the link to the original article in the post.
-   **Topics, not Hashtags:** Identify one relevant topic for the post. Your options are: Education, Story-telling, Analysis, Validation, and/or Promotion. DO NOT format them as #hashtags.

Finally, return the generated post and the topics in the required JSON format.

**Source Material (Content Idea):**
    ---
    {idea_content}
    ---
    This is the core content you will base the post on.
"""

        model = OpenAIModel(
            self.large_model_primary,
            provider=OpenRouterProvider(
                api_key=self.openrouter_api_key,
            ),
        )

        agent = Agent(
            model,
            output_type=GeneratedPost,
            model_settings=OpenAIModelSettings(
                temperature=self.large_model_temperature,
                extra_body={"models": self.large_models_fallback},
            ),
            system_prompt="",
        )

        result = await agent.run(prompt)
        return result.output
